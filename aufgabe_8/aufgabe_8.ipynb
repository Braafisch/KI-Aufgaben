{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Braafisch/KI-Aufgaben/blob/main/aufgabe_8/aufgabe_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdz14d76MKXk"
      },
      "outputs": [],
      "source": [
        "print(\"Berlin was geht ab!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise: k-armed bandits\n",
        "We use the 10-armed bandit testbed from Sutton & Barto 2020\n",
        "\n",
        "\n",
        "\n",
        "*   The true value q*\n",
        "(a) of each of the ten actions a is selected according to a normal distribution \n",
        "with mean 0 and unit variance\n",
        "*    The actual rewards are selected according to a mean q*\n",
        "(a), and are also unit-variance normal distributed, as suggested by these gray distributions. \n",
        "* Action-value estimates using the sample-average technique (with an initial estimate of 0)\n",
        "\n",
        "\n",
        "> 1.   Run 1000 time steps for the generated 10-armed bandit problems and action-value \n",
        "algorithms\n",
        "2.    Use 2000 randomly generated 10-armed bandit problems of this type.\n",
        "Run 1000 time steps for each of the 2000 randomly generated 10-armed bandit problems \n",
        "and action-value algorithms and average the results for each time step.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "a6SYk1DNMM9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import trange, tqdm\n",
        "\n",
        "from numpy.random import random\n",
        "from numpy.random import randint\n",
        "from numpy.random import normal"
      ],
      "metadata": {
        "id": "2ozciB-sMME8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_average(alpha,R,Q):\n",
        "  return alpha*(R-Q)\n",
        "\n",
        "def action_selection(Q,epsilon=0):\n",
        "      p = random()\n",
        "      if p < epsilon:\n",
        "        return randint(0,len(Q))\n",
        "      else:\n",
        "        ids = np.argwhere(Q[:,0] == np.amax(Q))\n",
        "        return ids[randint(0,ids.shape[0])] if ids.shape[0] > 1 else ids[0]\n",
        "\n",
        "def action_selection_UCB(Q,t,Nt,c=1):\n",
        "  Qtemp = np.copy(Q)\n",
        "  for a in range(10):\n",
        "    if Nt[a] == 0:\n",
        "      return a\n",
        "    if t > 0:\n",
        "      Qtemp[a] += c*np.sqrt(np.log(t)/Nt[a])\n",
        "    ids = np.argwhere(Qtemp[:,0] == np.amax(Qtemp))\n",
        "    if ids.shape[0] > 1:\n",
        "      return ids[randint(0,ids.shape[0])]\n",
        "    else:\n",
        "      return ids[0]\n",
        "\n",
        "def run(nr_runs,nr_steps,epsilon=0,new_rewards=False,alpha=None,UCB=False):\n",
        "  R_run = np.zeros((nr_runs,nr_steps))\n",
        "  for run in tqdm(range(nr_runs)):\n",
        "    Rewards = np.random.normal(0,1,[10,1])\n",
        "    Q = np.zeros((10,1),dtype=float) \n",
        "    N = np.zeros((10,1),dtype=int)\n",
        "\n",
        "    for step in range(nr_steps):\n",
        "      if step == 1000 and new_rewards:\n",
        "        Rewards[randint(0,10,5)] = normal(0,1,(5,1))\n",
        "      A = action_selection_UCB(Q,step,N) if UCB else action_selection(Q,epsilon=epsilon)\n",
        "      R = normal(Rewards[A],1,size=None)\n",
        "      N[A] += 1\n",
        "      Q[A] += sample_average(alpha, R, Q[A]) if alpha is not None else sample_average(1/N[A], R, Q[A])\n",
        "      R_run[run,step] = R\n",
        "\n",
        "  return R_run"
      ],
      "metadata": {
        "id": "C0JK-p0tPC29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run 1000 time steps for the generated 10-armed bandit problems and action-value algorithms"
      ],
      "metadata": {
        "id": "nJyLINr9eTZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = run(1,1000)\n",
        "np.savez('result_task_0_aufgabe_1.npz', Result=data)"
      ],
      "metadata": {
        "id": "8Uok1KtUPdL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use 2000 randomly generated 10-armed bandit problems of this type. Run 1000 time steps for each of the 2000 randomly generated 10-armed bandit problems and action-value algorithms and average the results for each time step."
      ],
      "metadata": {
        "id": "6Ud0KI3jeVJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = run(2000,1000)\n",
        "np.savez('result_task_0_aufgabe_2.npz',Results = data)"
      ],
      "metadata": {
        "id": "5cEVNFyhdkfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = range(1000)\n",
        "y = np.mean(data,axis=0)\n",
        "plt.plot(x,y,color='g')\n",
        "plt.xlim(0,1000)\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"optimal_action\")"
      ],
      "metadata": {
        "id": "SEaCleC2e44U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2\n",
        "Write a program that can reproduce the results of Sutton and Barto for the greedy and the ε-\n",
        "greedy algorithm ( ε = 0.1 and ε=0.01) as shown in the lecture."
      ],
      "metadata": {
        "id": "Tx5-1WNolOIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = run(2000,1000,0.1)\n",
        "np.savez('result_task_2_epsilon_10.npz',Results = data)\n",
        "data = run(2000,1000,0.01)\n",
        "np.savez('result_task_2_epsilon_1.npz',Results = data)"
      ],
      "metadata": {
        "id": "pmeWTpHblNOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3\n",
        "Change the maximum number of steps from 1000 to 2000.\n",
        "Do the ε-greedy algorithms ( ε = 0.1 and ε=0.01) converge?"
      ],
      "metadata": {
        "id": "Czt2az8ynA_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = run(2000,2000)\n",
        "np.savez('result_task_3_epsilon_0.npz',Results = data)\n",
        "data = run(2000,2000,0.1)\n",
        "np.savez('result_task_3_epsilon_10.npz',Results = data)\n",
        "data = run(2000,2000,0.01)\n",
        "np.savez('result_task_3_epsilon_1.npz',Results = data)"
      ],
      "metadata": {
        "id": "2GrENpcknJ8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 4\n",
        "Change the true value q*(a) of 5 randomly selected actions (out of the 10 actions) at time step\n",
        "1000 (i.e. now we have constructed a non-stationary problem). Run for 2000 time steps.\n",
        "Can you explain the behavior of the greedy and ε-greedy algorithms?"
      ],
      "metadata": {
        "id": "GCGQuP6FnPKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = run(2000,2000,new_rewards=True)\n",
        "np.savez('result_task_4_epsilon_0.npz',Results = data)\n",
        "data = run(2000,2000,0.1,True)\n",
        "np.savez('result_task_4_epsilon_10.npz',Results = data)\n",
        "data = run(2000,2000,0.01,True)\n",
        "np.savez('result_task_4_epsilon_1.npz',Results = data)"
      ],
      "metadata": {
        "id": "pXOt9k-pniRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 5\n",
        "Add the results of a weighted average method with α = 0.9 and ε-greedy (ε = 0.01) action\n",
        "selection to your final plot. Change the true value q*(a) as in task 4. What do you observe, especially comparing the sample average to the weighted average method of ε-greedy (ε = 0.01) action\n",
        "selection? Can you explain the behavior?"
      ],
      "metadata": {
        "id": "6GCBGFQdqO77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = run(2000,2000,0.1,True,0.9)\n",
        "np.savez('result_task_5_epsilon_0.npz',Results = data)\n",
        "data = run(2000,2000,0.1,True,0.9)\n",
        "np.savez('result_task_5_epsilon_10.npz',Results = data)\n",
        "data = run(2000,2000,0.01,True,0.9)\n",
        "np.savez('result_task_5_epsilon_1.npz',Results = data)"
      ],
      "metadata": {
        "id": "Gp8a5uAI2aPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 6 \n",
        "Add Upper-confident-bound action selection (UCB) c = 1 to your final plot. Change the true\n",
        "value q*(a) as in task 4."
      ],
      "metadata": {
        "id": "V-yvD9eI2_da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = run(2000,2000,0.1,True,UCB=True)\n",
        "np.savez('result_task_6_epsilon_0.npz',Results = data)\n",
        "data = run(2000,2000,0.1,True,UCB=True)\n",
        "np.savez('result_task_6_epsilon_10.npz',Results = data)\n",
        "data = run(2000,2000,0.01,True,UCB=True)\n",
        "np.savez('result_task_6_epsilon_1.npz',Results = data)"
      ],
      "metadata": {
        "id": "y7zT44vj3s0C"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "9da9d52195322e173d33ae2e6a5687ee9810f43282d66f05579a543f3ee9968b"
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "aufgabe_8.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}